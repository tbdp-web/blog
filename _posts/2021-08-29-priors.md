---
published: true
title: Setting Priors 2.0
tags: ["epistemology"]
---
I was watching a video from digital gnosis about the Bayesian approach that the McGrews used to attempt to prove the historicity of the resurrection of Jesus Christ of Nazareth, and I decided to construct a little guide on how to set your priors properly in a philosophical discussion, since one of the things that the hosts noted is that the McGrew's completely left out considering priors or any discussion of how to set them, when priors are often one of the most important and most often forgotten components of doing proper abductive reasoning.

Obviously, setting priors in the context of a philosophical discussion is going to be far less of an exact science and far more of a heuristic than in the context of true statistical analysis. As such, the way I recommend you view this guide is more as a list of things to remember to check when deciding on the prior probability / plausibility of a certain hypothesis, as well as a way to conceptualize how they should be weighted relative to each other. In a similar way, when assessing the likelihood of a given piece of evidence given a certain hypothesis, and if philosophical discussion one cannot come up with the exact probabilities in the way that you can in a statistical analysis, but you can roughly speaking estimate the relative size of the probability in comparison to the size of the prior probability. All that's important here is whether the probability of the evidence given a certain hypothesis overcomes the prior implausibility of the hypothesis itself, which is a relative judgment and not an absolute one. Of course, having concrete numbers would be very useful to determine what your posterior probability is, but you can't have everything. Again, think of Bayesian reasoning as a whole, not just my list of things that you should use when considering your priors, as more of a heuristic that reminds you to consider all facets of a certain hypothesis, instead of only considering the probability of the evidence given the hypothesis, which people often do and which is a noted cognitive bias in human beings.

So, what is this list? Here it is, in order of relative weight:

1. Metaphysical burden or price tag: the more new types of objects one must introduce in order to construct one hypothesis, the less likely It is that the hypothesis will be correct as far as your priors are concerned. By types of objects, I mean new ontological or metaphysical types with different laws and behaviors: New types of matter, for instance, or even things that are not matter at all such as the supernatural. Note that the less demonstrated this new type of thing is, or the more different it is from types of things that have been demonstrated to exist in the past, the greater the burden of the individual type will be as well.
2. Propositional complexity: since the probability of the conjunction of two propositions being true Is less than the probability of either of the two propositions alone being true, the more propositions one must put in conjunction together in order to construct and describe your hypothesis, the less intrinsically likely it is that your hypothesis is correct. Note that this can be overcome if the propositions one is conjugating our inherently themselves very likely, such that a very long chain of extremely likely a propositions may be just as inherently plausible as a very short chain of incredibly unlikely propositions, we're likelihood is determined of course by the amount of demonstrations we have of either that proposition being true or, alternatively, but less effectively, similar propositions being true. Also note that propositions that are derived from other propositions do not count when analyzing propositional complexity, as their inherent probability is not unique and so to include them in the probability of the conjunction overall would be to double count, as it would essentially be counting the probability of the propositions that this new proposition is derived from twice, once for the original propositions and once for the derived one. Thus a hypothesis that has very few basic propositions that describe it, but the propositions of which are very fertile and can lead to a lot of results should not be penalized for this. In fact, hypotheses like these, when the derived propositions are actually descriptive of evidence, should be vastly preferred.
3. Post Hocness: The more a hypothesis is arbitrarily fitted to a set of evidence, less likely it is that that hypothesis will actually be predictive for further events, as it will become more and more overfitted to one particular event. Furthermore, oftentimes when this overfitting occurs, it leads to a hypothesis where the underlying causal mechanism posited in order to explain the events falls to the wayside and is only paid lip service to, while most of the evidence is simply positive as brute facts somewhat related to this under explained underlying mechanism, whereas the entire point of building hypotheses in order to figure out what the best explanation is for a set of data is in order to come up with a set of robust causal mechanisms underneath the evidence we have in order to understand how things will happen going forward and be able to interact with them. Additionally, this is extremely likely to happen when what we are talking about and trying to build a hypothesis about is a single event that will only happen one time and of which there are no other similar events known to us either, such as the beginning of the universe; hence hypotheses that are designed to explain a singular event of which there are no similar events known to us should be viewed with higher suspicion and higher intrinsic improbability.
4. Expected evidence: This is a criteria that may not belong on this list, as if you count a lack of evidence as a form of evidence you can instead use instances of a lack of evidence as evidence that is more or less likely under a given hypothesis and use it directly in the theorem instead of putting in the priors, but that seems like a very odd thing to do, so I'll include this as something you should think about for your priors instead. Essentially, if a given hypothesis leaves you to expect their to be evidence in certain areas or in certain ways, especially if it leads you to expect a lot of very prominent and easily accessible evidence, and that evidence cannot be found, then that means that the hypothesis has a pretty high intrinsic improbability, because it had very many chances to provide evidence that would have raised its posterior probability but did not do so. How you calculate the amount of chances it had versus the amount of times that an event happened that was slightly more probable given that hypothesis instead of another one is pretty much up to you, and I would be extremely careful using this criteria heavily when deciding your priors, as depending on how you could do it it could have a disproportionate effect. Furthermore depending on the hypothesis, this can become a very important criteria.


Hope that's as interesting.