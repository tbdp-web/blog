---
published: false
title: Egoism and Game Theory Speculation
---

One thing I've been thinking about recently is game theory and how it affects the dominant strategy of a materialistic/simplistic egoist with regards to harming others, as well as how Nash equilibria affect the general outcome of the society composed of such egoists. I haven't been able to rigorously do the game theory, decision theory, and mathematics necessary to come to a certain and rigorous conclusion about these things, but I can put some of my rambling thoughts here so that I can have something somewhere to keep my notes on it.

## The Iterated Prisoner's Dilemma and Egoism
The game theory side is pretty simple. We've been doing iterated prisoners dilemma competitions for several decades now, and a version of tit for tat that has a 5 to 10% probability of forgiving the other player has emerged as universally the most successful strategy for gaining overall points. Basically that what that means is that this algorithm will begin by treating the other player in the game positively by cooperating, and will only switch to harming the other player if the other player harms it first.

Then, after it harms the other player for one turn, it will return to cooperating if the other player does so as well. However, 5 to 10% of the time it will not switch to harming the other player if it itself is harmed. This prevents a downward infinite spiral if the other player you're playing with is a tit for tat or grim trigger player. Notice that this is the best strategy overall because it can deal with defect players, tit for tat players, grim trigger players, and although it won't take maximum advantage of altruistic players, the fact that itself cannot be taken advantage of either and that it will cooperate in cases where the other player would not always cooperate, means that in general it ends up maximizing its points system.

What implication does this have for the materialistic egoist? Well, and the world we live in, most people are tit for tat or grim trigger or defect players. Almost nobody is a pure altruistic player. Therefore, if the best strategy against a mix of strategies that are mostly not altruistic is tit for tat with forgiveness in an iterated prisoners dilemma, then the same should hold true for general interactions, since just like in our prisoners dilemma, in general interactions when people cooperate generally they have greater outcomes than when both of them defect against each other, although if one person harms the other but is not himself harmed he might come out better overall. In actuality however, in real life, it's actually more positive than the prisoner's dilemma: First of all, you can often communicate with the other player beforehand to figure out what they're going to do. Second of all, and more importantly, oftentimes two people cooperating can actually produce more benefit for both of them individually than the benefit that one of them would get by defecting against the other with the other being altruistic. This is why wealth is not a fixed pie, where one person has to be harmed in order for another person to be benefited, but a growing pie, which results from the fact that when people cooperate they actually end up with more wealth overall than if people just took wealth from others.

Now there are some possible objections to my application of what we have learned from game theory directly to materialistic egoism in the real world. First and most importantly, we may not find ourselves in a repeated game with the same player, unlike in an iterated prisoner's dilemma. Second, we might find ourselves in a position where harming and other person could not lead to them harming us because they would have no ability to retaliate, and where cooperation with them would not yield more benefit for the egoists then simply harming them.
My response to the first objection is twofold. First, although we might may not find ourselves in repeated game with a single person, we do not know that we will not, And actually an important component of the iterated prisoners dilemma leading to tit for tat as being the ideal strategy is that the number of iterations that one will play with some person is completely unknown. Furthermore, the times that a person interacts with another person do not have to be sequential for that interaction to be iterated. You never know when you will have to interact with another person again, especially if they exist in spaces that you are often also in, or can influence things that in turn influence you. Furthermore, and perhaps more importantly, although one may not end up playing an indefinite iterated game with another person, you can also develop a reputation based on how that person reports your actions to others, and that reputation will import your actions in all of the games that you've played with everyone into the interaction with the next person that you interact with, making all the interactions you've ever had with everyone technically part of the same iterated game. This can be neutralized by ensuring that your reputation does not spread, but that is extremely difficult to do and the effort that you would have to put in to prevent that and might be more than you would gain from not simply adhering to tit for tat as a strategy.

My response to the second objection is that you rarely know when a person will be able to get back at you, so tit for tat is generally a good rule of thumb. Additionally, even if that particular person can't get back at you, reputation is still a factor. On top of that, people that cannot retaliate can simply be counted as purely altruistic actors in the context of the iterated prisoners dilemma game, and those are already factored into that game when talking about tit for tat being the optimal overall strategy anyway, so it doesn't really change the applicability of the solution to the iterated prisoners dilemma to an egoists interactions. Additionally, people who are unable to directly get back at you, but who were harmed by you, are extremely likely to spread information about your actions and attempted to ruin your reputation, as they would have no other mechanism by which to get back at you then that, so although that person might not get back at you, other people probably will.
Additionally, people can also retaliate by simply quitting the game entirely, which is not something that can even happen in iterated prisoners dilemma at all. If people become aware of the fact that you are going to harm them and not cooperate, they will simply avoid entering the game with you and you'll lose a lot of opportunities.
Again, it is possible to construct a situation in which one can avoid these game theoretic incentives. For instance, if one becomes a warlord or a mob boss or a dictator, or something along those lines anyway, one can probably avoid these incentives by converting everyone in your vicinity into altruistic actors because you have so much power that they can't possibly retaliate against you. The problem with this strategy is of course that most people aren't really capable of doing it, and it's extremely difficult as well, and perhaps not actually that rewarding. On top of that, generally people that attempt to do this are eventually brought down anyway, and it is doubtful to me whether the game that they had while they were in power is worth the downfall, especially since why are they were in power they would have to be constantly fighting and worrying in order to keep themselves in power.

## Society and the Egoist
There are more considerations as well. First of all, most people are not purely altruistic actors, And it is likely not possible to convince them to be so either. When experiments were performed on actual people playing the iterated prisoners dilemma, for instance, the most common strategies were to always defect, tit for tat, or grim trigger. This indicates that most people find non altruistic strategies intuitively most likely to be advantageous, or the most fair and satisfying anyway, and it will be impossible to convince everyone to be altruistic towards you. Thus while it might be in the best interest of the egoist to convince everyone in society to be altruistic except them, this is not a plausible or possible feat.
The second thing that a materialistic egoist would have to concern themselves with is the fact that all human beings naturally desire the maximum wealth and influence, and also desire to defend that wealth and influence, as well as their own person, as effectively as possible. This is true just as much for non-egoists as egoists, but for simplicity's sake I will assume an entire society of egoists. Now generally speaking, no person is able to defend very much alone. Therefore, to defend more wealth, they will have to seek the aid of others in defending it. Those others however, would themselves want their own person and wealth defended, and would not agree to do for another what they could not do for themselves, since any benefit they could get from defending the person and wealth of another would mean nothing if that benefit could simply be taken away again because they could not defend their own person or wealth. Hence, unless one could convince all these egoists that one somehow had a "divine right" to rule them and thus get more defense of wealth from them than they got from him, the most natural situation is one in which there is some sort of mutual defense of person and maximum wealth, such that if I agree to defend your person and wealth, you agree to either provide me with such a means that I can also defend my person and wealth, or you yourself will defend my person and wealth. So either it will lead to private protection agencies or mutual defense agencies ([possibly relevant article by David Friedman](http://www.daviddfriedman.com/Academic/FeudThenandNow.html)).

The next problem, however, is that everyone involved in this would want the maximum amount of wealth possible for them, even wealth that might be considered associated with others, if possible. So why would we expect this to lead to something like private property rights? Well, because people even inside a private protection agency or mutual defense agency, not to mention people between differing agencies of those sorts, would have to come to some agreement as to whose property to assign to whom, in order to avoid constant warfare or the collapse of their mutual defense agencies, which is worse for everyone because it decreases the overall amount of wealth that is generated and is dangerous in many respects.

This, plus the equality point I outlined above, could lead to two outcomes: either a principle of property rights is outlined, and the same *principle* is applied to everyone, or, everyone only has the same *amount* of property defended as everyone else has. They would want a unified rule (whether by principle or by amount) for everyone because the weaker parties would only want to enforce a principle that benefitted those more powerful if it allowed them to possibly achieve that power too, and because getting to parties to agree to a principle that disadvantages one of them is basically impossible, so since collectively the weaker parties are just as powerful as the fewer but more powerful parties, you would probably end up with equal treatment for both, unless beliefs like divine rights intervene. So either you get a system that operates on a certain consistent principle for everyone (equality) or a system that ensures a consistent amount of wealth for everyone (equity). I think, however, that an egoist would choose the former option, as it would allow him the possibility of rising above the average amount of per capita wealth in the organization in return for only the possibility of falling below the average as well, and having to contribute to the organization, which redounds to his own benefit in part anyway. Perhaps there would be the expectation that those who benefit more from the organization contribute more to it, and perhaps there might also be the expectation that some of the wealth and time contribute to the organization might also go to supporting those who have fallen below the average, but overall the most rewarding strategy would be to apply the same principle to everyone, and have it be a principle that allows for (unbounded, to maximize the possible payoff) inequality.
What would this unified principle look like? Now the one thing that people would be least likely to be willing to give up would be property that they directly labored to either earn from others or to produce themselves, whereas claims over property which has nothing necessarily to do with them at all, while desirable, would not be as likely to be closely held onto, and so would be more up for relinquishment in the process of mutual bargaining. Furthermore, property that is directly associated with one person, either through them laboring to produce it, laboring to earn it, or being the first user and appropriator of it, is a very convenient Schelling point that is uniquely determined and easy to understand when compared to other conceptions of whose property is whose. ([DF has a similar opinion](http://www.daviddfriedman.com/Academic/Property/Property.html)).

An additional point is that it would be in the interest of everyone in an egoist society to want the maximum defense for themselves and to therefore construct and contribute to organizations as much as possible that would track down those who harm them. If everyone or nearly everyone had such organizations however, it would suddenly not become very profitable for the egoist himself to harm others, since they would have their own organizations in order to prevent that.